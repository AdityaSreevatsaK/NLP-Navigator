{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830a2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "\n",
    "from time import time\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Embedding,Bidirectional\n",
    "from tensorflow.keras.models import Sequential \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d8df39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4\n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Very cute, very comfortable. for me aesthetics...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Cropped and wide- would look cuter on someone ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Review Text  Rating\n",
       "497  Very cute, very comfortable. for me aesthetics...       5\n",
       "498  Cropped and wide- would look cuter on someone ...       3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_data = pd.read_csv(\"../b. Datasets/Online Shopping Reviews.csv\")\n",
    "display(review_data.head(2))\n",
    "display(review_data.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da2b55a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data['Emotion'] = np.where(review_data['Rating'] > 3, 'Positive', 'Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35bb72a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating   Emotion\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4  Positive\n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5  Positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Very cute, very comfortable. for me aesthetics...</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Cropped and wide- would look cuter on someone ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Review Text  Rating   Emotion\n",
       "497  Very cute, very comfortable. for me aesthetics...       5  Positive\n",
       "498  Cropped and wide- would look cuter on someone ...       3  Negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(review_data.head(2))\n",
    "display(review_data.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68583dc5",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a73033da",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data['Review Text'] = review_data['Review Text'].astype(str).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc2eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data['Review Text'] = review_data['Review Text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ac34e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('absolutely', 12),\n",
       " ('wonderful', 9),\n",
       " ('silky', 2),\n",
       " ('and', 1099),\n",
       " ('sexy', 9)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokeniser = Tokenizer()\n",
    "tokeniser.fit_on_texts(review_data['Review Text'])\n",
    "list(tokeniser.word_counts.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18693fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absolutely wonderful  silky and sexy and comfo...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love this dress  its sooo pretty  i happened t...</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating   Emotion\n",
       "0  absolutely wonderful  silky and sexy and comfo...       4  Positive\n",
       "1  love this dress  its sooo pretty  i happened t...       5  Positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuations(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "review_data['Review Text'] = review_data['Review Text'].apply(remove_punctuations)\n",
    "review_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b274bd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absolutely wonderful silky sexy comfortable</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love dress sooo pretty happened store im glad ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating   Emotion\n",
       "0        absolutely wonderful silky sexy comfortable       4  Positive\n",
       "1  love dress sooo pretty happened store im glad ...       5  Positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords_function(text):\n",
    "    return remove_stopwords(text)\n",
    "\n",
    "review_data['Review Text'] = review_data['Review Text'].apply(remove_stopwords_function)\n",
    "review_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3dcdf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absolutely wonderful silky sexy comfortable</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love dress sooo pretty happen store im glad bc...</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating   Emotion\n",
       "0        absolutely wonderful silky sexy comfortable       4  Positive\n",
       "1  love dress sooo pretty happen store im glad bc...       5  Positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>cute comfortable aesthetic comfort hand hand d...</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>crop wide look cuter petite wide crop sheer</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Review Text  Rating   Emotion\n",
       "497  cute comfortable aesthetic comfort hand hand d...       5  Positive\n",
       "498        crop wide look cuter petite wide crop sheer       3  Negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wordnet_lemmatiser = WordNetLemmatizer()\n",
    "wordnet_map = {\n",
    "    'N': wordnet.NOUN,\n",
    "    'J': wordnet.ADJ,\n",
    "    'V': wordnet.VERB,\n",
    "    'R': wordnet.ADV\n",
    "}\n",
    "\n",
    "def lemmatise_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return ' '.join([wordnet_lemmatiser.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "review_data['Review Text'] = review_data['Review Text'].apply(lemmatise_words)\n",
    "display(review_data.head(2))\n",
    "display(review_data.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd5bac",
   "metadata": {},
   "source": [
    "## Word2Vec = CBOW (Continuous Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45847d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable'],\n",
       " ['love',\n",
       "  'dress',\n",
       "  'sooo',\n",
       "  'pretty',\n",
       "  'happen',\n",
       "  'store',\n",
       "  'im',\n",
       "  'glad',\n",
       "  'bc',\n",
       "  'order',\n",
       "  'online',\n",
       "  'bc',\n",
       "  'petite',\n",
       "  'buy',\n",
       "  'petite',\n",
       "  '58',\n",
       "  'love',\n",
       "  'length',\n",
       "  'hit',\n",
       "  'little',\n",
       "  'knee',\n",
       "  'definitely',\n",
       "  'true',\n",
       "  'midi',\n",
       "  'truly',\n",
       "  'petite']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = []\n",
    "for word in review_data['Review Text']:\n",
    "    token_list.append(RegexpTokenizer('\\w+').tokenize(word))\n",
    "\n",
    "token_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6997fdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build and train the CBOW model vocabulary 1.58 mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "cbow_model = Word2Vec(min_count=2, window=2, sg=0, sample=5e-5, alpha=0.05, min_alpha=0.0005, negative=20)\n",
    "cbow_model.build_vocab(token_list)\n",
    "cbow_model.train(token_list, total_examples=cbow_model.corpus_count, epochs=5000, report_delay=1)\n",
    "print(\"Time to build and train the CBOW model vocabulary {} mins\".format(round((time()-start_time)/ 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d183d62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.4970006e-01,  1.4481029e-01, -3.3299336e-01,  1.0815486e+00,\n",
       "        1.8659927e-01,  9.7541157e-03, -6.1849755e-01, -2.2549291e-01,\n",
       "       -8.1570365e-02, -1.5310153e-02, -6.0348469e-01,  4.1442069e-01,\n",
       "       -4.2936131e-02,  5.9963572e-01, -1.6378808e-01, -8.6428243e-01,\n",
       "        5.3765021e-02,  3.8537908e-01, -1.8285264e-01, -5.0456357e-01,\n",
       "       -8.5532641e-01,  3.9504370e-01, -7.6105124e-01, -3.4410292e-01,\n",
       "        1.1005403e+00, -1.0346520e-01,  1.6382396e+00,  2.4964552e-01,\n",
       "       -6.5069997e-01, -5.0101840e-01,  1.9166665e-02,  6.8660438e-02,\n",
       "        2.0231715e-01,  1.0029162e-01, -3.1870019e-01,  1.5651911e-01,\n",
       "       -3.4575057e-01,  6.4419933e-02,  2.8742218e-02, -4.6252999e-02,\n",
       "        8.0844849e-02,  6.9430369e-01,  8.5663341e-02,  4.1341874e-01,\n",
       "        4.1485196e-01,  5.3475875e-01,  3.8409519e-01, -7.9785541e-02,\n",
       "        1.3393161e-01,  1.8016180e-01, -7.2145587e-01, -7.5172198e-01,\n",
       "        9.7166888e-02,  4.8654845e-01, -9.1107255e-01, -8.1156361e-01,\n",
       "       -2.8877902e-01,  3.4151536e-01, -4.6993813e-01, -4.6860468e-01,\n",
       "        3.2264078e-01, -3.0536613e-01, -4.7861156e-01,  8.1433257e-04,\n",
       "       -4.6760496e-01, -6.1292088e-01, -1.3567053e-01,  1.8084054e-01,\n",
       "       -8.4204102e-01, -2.2230569e-01, -2.5262332e-01,  1.1543729e-01,\n",
       "        7.7951074e-01, -3.1056675e-01, -4.0609255e-01, -3.4426779e-01,\n",
       "       -2.8716978e-01,  1.2474408e+00, -7.2466880e-02, -1.4255571e-01,\n",
       "        4.3891162e-01,  2.3317920e-01, -6.5948114e-02,  3.8956836e-01,\n",
       "       -2.6510170e-01,  1.7205103e-01, -2.8932828e-01,  1.2871391e+00,\n",
       "       -2.3121841e-02, -5.4119498e-01,  3.9420110e-01,  4.4951168e-01,\n",
       "       -7.0754558e-01, -1.1522019e+00, -2.3995382e-01, -5.1310938e-02,\n",
       "       -1.0012902e+00, -1.4896475e-01,  3.6733213e-01, -3.9852120e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_model.wv.__getitem__('look')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3738386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using word embedding vocabulary model to find top 5 similar words to the word `comfort`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('wonderfully', 0.4730899930000305),\n",
       " ('machine', 0.3544391393661499),\n",
       " ('band', 0.3534582555294037),\n",
       " ('sleep', 0.35129183530807495),\n",
       " ('charm', 0.3066907525062561)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Using word embedding vocabulary model to find top 5 similar words to the word `comfort`')\n",
    "cbow_model.wv.most_similar('comfort', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b83c43dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using word embedding vocabulary model to find top 5 similar words to the word `order`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('size', 0.5465220808982849),\n",
       " ('im', 0.43615227937698364),\n",
       " ('large', 0.43381091952323914),\n",
       " ('small', 0.43364858627319336),\n",
       " ('fit', 0.4155549705028534)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Using word embedding vocabulary model to find top 5 similar words to the word `order`')\n",
    "cbow_model.wv.most_similar('order', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b286f59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((399, 2), (100, 2), (399,), (100,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = review_data.drop(columns='Emotion', axis=0)\n",
    "y = review_data['Emotion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b360e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes ['Negative' 'Positive']\n",
      "Encoding labels [1 1 0 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_encoding = encoder.fit_transform(y)\n",
    "\n",
    "print(\"Classes\", encoder.classes_)\n",
    "print(\"Encoding labels\", y_encoding[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8261d177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 2178\n",
      "\n",
      "X Sequences - First 5: [[205, 263, 739, 264, 36], [4, 5, 24, 486, 50, 10, 157, 414, 14, 60, 414, 26, 16, 26, 265, 4, 38, 121, 13, 149, 65, 56, 580, 353, 26], [122, 309, 5, 42, 21, 740, 14, 26, 9, 123, 1, 9, 9, 310, 266, 581, 26, 51, 354, 166, 244, 36, 2, 129, 244, 68, 103, 415, 177, 741, 103, 63, 582, 741, 103, 742, 206, 487], [4, 4, 4, 743, 135, 583, 584, 66, 6, 12, 104], [15, 20, 744, 167, 27, 38, 6, 288, 585, 116, 586, 4, 15]]\n",
      "\n",
      "X Padded - First 2: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 205\n",
      "  263 739 264  36]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   5  24\n",
      "  486  50  10 157 414  14  60 414  26  16  26 265   4  38 121  13 149  65\n",
      "   56 580 353  26]]\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 40\n",
    "MAX_WORDS = 1000\n",
    "\n",
    "tokeniser = Tokenizer(num_words=MAX_WORDS)\n",
    "tokeniser.fit_on_texts(X[\"Review Text\"])\n",
    "vocab_size = len(tokeniser.word_index)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "X_sequences = tokeniser.texts_to_sequences(X[\"Review Text\"])\n",
    "print(\"\\nX Sequences - First 5:\", X_sequences[:5])\n",
    "\n",
    "X_padded = pad_sequences(X_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print(\"\\nX Padded - First 2:\", X_padded[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43a10f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('size', 1), ('fit', 2), ('look', 3), ('love', 4), ('dress', 5)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokeniser.word_index.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3a97e-1516-4405-aa83-5e00e3929ff1",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad12e8db-d814-4f23-8569-818fe8509c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoding, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d880005",
   "metadata": {},
   "source": [
    "## Building an Bidirectional LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3761c4eb-d333-4175-b831-b9d88f95086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = cbow_model.vector_size\n",
    "word_index = tokeniser.word_index\n",
    "embedding_matrix = np.zeros((len(word_index)+1, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in cbow_model.wv:\n",
    "        embedding_matrix[i] = cbow_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60a617c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(word_index)+1, \n",
    "                    output_dim=embedding_dim, \n",
    "                    weights=[embedding_matrix], \n",
    "                    input_length=MAX_SEQUENCE_LENGTH, \n",
    "                    trainable=True))\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=False), merge_mode='concat'))\n",
    "model.add(tf.keras.layers.Dense(len(word_index)+1, activation='softmax'))\n",
    "model.build(input_shape=(None, MAX_SEQUENCE_LENGTH))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef9854dc-4f0d-4d5d-96fd-8906efb57f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">217,900</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">731,136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2179</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,117,827</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │         \u001b[38;5;34m217,900\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m731,136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2179\u001b[0m)                │       \u001b[38;5;34m1,117,827\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,066,863</span> (7.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,066,863\u001b[0m (7.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,066,863</span> (7.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,066,863\u001b[0m (7.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b80c2a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 225ms/step - accuracy: 0.4341 - loss: 6.9260 - val_accuracy: 0.7900 - val_loss: 1.1930\n",
      "Epoch 2/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.7917 - loss: 1.0333 - val_accuracy: 0.8200 - val_loss: 0.6177\n",
      "Epoch 3/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.6688 - loss: 0.6143 - val_accuracy: 0.7900 - val_loss: 0.5855\n",
      "Epoch 4/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.8111 - loss: 0.4883 - val_accuracy: 0.8000 - val_loss: 0.5307\n",
      "Epoch 5/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.7984 - loss: 0.5133 - val_accuracy: 0.7900 - val_loss: 0.5470\n",
      "Epoch 6/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - accuracy: 0.7909 - loss: 0.5044 - val_accuracy: 0.8200 - val_loss: 0.4970\n",
      "Epoch 7/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - accuracy: 0.8202 - loss: 0.4279 - val_accuracy: 0.8100 - val_loss: 0.4701\n",
      "Epoch 8/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - accuracy: 0.8415 - loss: 0.3914 - val_accuracy: 0.8200 - val_loss: 0.4636\n",
      "Epoch 9/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.8432 - loss: 0.3697 - val_accuracy: 0.8300 - val_loss: 0.4370\n",
      "Epoch 10/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.8700 - loss: 0.2937 - val_accuracy: 0.8400 - val_loss: 0.4292\n",
      "Epoch 11/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.9098 - loss: 0.2980 - val_accuracy: 0.8500 - val_loss: 0.4414\n",
      "Epoch 12/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.8992 - loss: 0.2560 - val_accuracy: 0.8400 - val_loss: 0.4861\n",
      "Epoch 13/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.9284 - loss: 0.2107 - val_accuracy: 0.8300 - val_loss: 0.5380\n",
      "Epoch 14/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - accuracy: 0.9227 - loss: 0.2119 - val_accuracy: 0.8200 - val_loss: 0.4550\n",
      "Epoch 15/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9526 - loss: 0.1624 - val_accuracy: 0.8200 - val_loss: 0.4835\n",
      "Epoch 16/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.9667 - loss: 0.1246 - val_accuracy: 0.8300 - val_loss: 0.5205\n",
      "Epoch 17/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.9770 - loss: 0.0816 - val_accuracy: 0.8400 - val_loss: 0.5609\n",
      "Epoch 18/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - accuracy: 0.9725 - loss: 0.0792 - val_accuracy: 0.8400 - val_loss: 0.6078\n",
      "Epoch 19/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9917 - loss: 0.0489 - val_accuracy: 0.7700 - val_loss: 0.5457\n",
      "Epoch 20/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.9940 - loss: 0.0394 - val_accuracy: 0.8100 - val_loss: 0.6319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d957668450>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, verbose=True, batch_size=32, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3cb2aa2-1ae2-4b84-9d67-215292c67b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ba6024a-b2a4-4cfc-b533-7c6fb147d371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8198 - loss: 0.4917\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d23835-75a7-472c-90f2-7a9a6f23c24f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
